{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9 Study Notebook\n",
    "\n",
    "# UC San Diego OMDS DSC 207"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ASSIGNMENT CONFIG\n",
    "init_cell: false\n",
    "requirements: requirements.txt\n",
    "solutions_pdf: true\n",
    "check_all_cell: false\n",
    "show_question_points: false\n",
    "export_cell: false\n",
    "generate: \n",
    "    pdf: true\n",
    "    filtering: true\n",
    "    pagebreaks: true\n",
    "    zips: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Instructions-\n",
    "1. You may use any visualization tool - seaborn/matplotlib for a task\n",
    "2. Sample outputs are provided but your output may vary based on choice of library and parameters.\n",
    "3. Use the mandatory parameter values wherever specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Otter-Grader\n",
    "\n",
    "In this course, we will be using Otter-Grader to evaluate your code using predefined test cases. Otter-Grader is a powerful tool that helps you check your work before submitting assignments. To get started with Otter-Grader, you need to install it in your Jupyter Notebook environment.\n",
    "\n",
    "To install Otter-Grader, simply run the below code cell. In case, an error occurs related to wget command, please refer to the below link: https://www.jcchouinard.com/wget/. The tool may not be installed in your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: otter-grader in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (5.2.2)\n",
      "Requirement already satisfied: dill in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (0.3.7)\n",
      "Requirement already satisfied: jinja2 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (3.1.2)\n",
      "Requirement already satisfied: nbformat in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (5.9.2)\n",
      "Requirement already satisfied: pandas in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (2.0.3)\n",
      "Requirement already satisfied: PyYAML in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (6.0.1)\n",
      "Requirement already satisfied: python-on-whales in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (0.65.0)\n",
      "Requirement already satisfied: requests in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (2.31.0)\n",
      "Requirement already satisfied: wrapt in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (1.14.1)\n",
      "Requirement already satisfied: jupytext in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (1.15.2)\n",
      "Requirement already satisfied: click in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (8.1.7)\n",
      "Requirement already satisfied: fica>=0.3.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (0.3.1)\n",
      "Requirement already satisfied: ipython in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (8.15.0)\n",
      "Requirement already satisfied: astunparse in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (1.6.3)\n",
      "Requirement already satisfied: ipywidgets in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (8.1.1)\n",
      "Requirement already satisfied: ipylab in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (1.0.0)\n",
      "Requirement already satisfied: nbconvert in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from otter-grader) (7.8.0)\n",
      "Requirement already satisfied: docutils in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from fica>=0.3.0->otter-grader) (0.20.1)\n",
      "Requirement already satisfied: sphinx in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from fica>=0.3.0->otter-grader) (7.2.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from astunparse->otter-grader) (0.41.2)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from astunparse->otter-grader) (1.16.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipywidgets->otter-grader) (0.1.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipywidgets->otter-grader) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipywidgets->otter-grader) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipywidgets->otter-grader) (3.0.9)\n",
      "Requirement already satisfied: backcall in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from ipython->otter-grader) (0.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jinja2->otter-grader) (2.1.3)\n",
      "Requirement already satisfied: toml in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jupytext->otter-grader) (0.10.2)\n",
      "Requirement already satisfied: markdown-it-py>=1.0.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jupytext->otter-grader) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jupytext->otter-grader) (0.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (5.3.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (0.8.0)\n",
      "Requirement already satisfied: packaging in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (23.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbconvert->otter-grader) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbformat->otter-grader) (2.18.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbformat->otter-grader) (4.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from pandas->otter-grader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from pandas->otter-grader) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from pandas->otter-grader) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from pandas->otter-grader) (1.26.0)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=1.5 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from python-on-whales->otter-grader) (2.4.2)\n",
      "Requirement already satisfied: tqdm in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from python-on-whales->otter-grader) (4.66.1)\n",
      "Requirement already satisfied: typer>=0.4.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from python-on-whales->otter-grader) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from python-on-whales->otter-grader) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from requests->otter-grader) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from requests->otter-grader) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from requests->otter-grader) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from requests->otter-grader) (2023.7.22)\n",
      "Requirement already satisfied: webencodings in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->otter-grader) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jedi>=0.16->ipython->otter-grader) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->otter-grader) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->otter-grader) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->otter-grader) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat->otter-grader) (0.10.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jupyter-core>=4.7->nbconvert->otter-grader) (3.10.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from markdown-it-py>=1.0.0->jupytext->otter-grader) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from nbclient>=0.5.0->nbconvert->otter-grader) (8.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from pexpect>4.3->ipython->otter-grader) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->otter-grader) (0.2.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from pydantic!=2.0.*,<3,>=1.5->python-on-whales->otter-grader) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from pydantic!=2.0.*,<3,>=1.5->python-on-whales->otter-grader) (2.10.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->otter-grader) (2.5)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (1.0.7)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (1.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (2.0.4)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (1.1.9)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (1.0.6)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (2.12.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (0.7.13)\n",
      "Requirement already satisfied: imagesize>=1.3 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from sphinx->fica>=0.3.0->otter-grader) (1.4.1)\n",
      "Requirement already satisfied: executing in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from stack-data->ipython->otter-grader) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from stack-data->ipython->otter-grader) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from stack-data->ipython->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->otter-grader) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/ananshar/anaconda3/envs/ta_env/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->otter-grader) (6.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY\n",
    "%pip install otter-grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with `nltk`\n",
    "\n",
    "`nltk` is the most popular Python package for Natural Language processing, it provides algorithms for importing, cleaning, pre-processing text data in human language and then apply computational linguistics algorithms like sentiment analysis.\n",
    "\n",
    "It also includes many easy-to-use datasets in the `nltk.corpus` package, we can download for example the `movie_reviews` package using the `nltk.download` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the Movie Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below line and run this cell if you need to install nltk\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell for all the imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/ananshar/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this cell to download the dataset\n",
    "nltk.download(\"movie_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list and download other datasets interactively, just type:\n",
    "\n",
    "`nltk.download()`\n",
    "    \n",
    "in the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to import the dataset\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ananshar/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ananshar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this cell for later use in tokenization\n",
    "nltk.download('vader_lexicon')  # for sentiment analysis\n",
    "nltk.download('punkt')  # for tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenize Text in Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "romeo_text = \"\"\"Why then, O brawling love! O loving hate!\n",
    "O any thing, of nothing first create!\n",
    "O heavy lightness, serious vanity,\n",
    "Misshapen chaos of well-seeming forms,\n",
    "Feather of lead, bright smoke, cold fire, sick health,\n",
    "Still-waking sleep, that is not what it is!\n",
    "This love feel I, that feel no love in this.\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1\n",
    "points: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in Natural Language processing is generally to split the text into words, this process might appear simple but it is very tedious to handle all corner cases, see for example all the issues with punctuation we have to solve if we just start with a split on whitespace.\n",
    "\n",
    "1.1 **Split `romeo_text` by spaces and store the resultant list of words in the variable `romeo_tokens`** [0.5 pt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "romeo_tokens = romeo_text.split()\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "romeo_tokens = ...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(romeo_tokens) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(romeo_tokens) == 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "ans_1 = romeo_text.split()\n",
    "assert sorted(ans_1) == sorted(romeo_tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q2\n",
    "points: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nltk` has a sophisticated word tokenizer trained on English named `punkt` which we imported earlier in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2  **Use the `nltk.word_tokenize(text)` function to properly tokenize `romeo_text` and stores the result as `romeo_words`. Print the resultant list.** Compare it to the whitespace splitting we used above and mention the difference. [0.5 pt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "romeo_words = nltk.word_tokenize(romeo_text)\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "romeo_words = ...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(romeo_words) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(romeo_words) == 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "ans_2 = nltk.word_tokenize(romeo_text)\n",
    "assert sorted(ans_2) == sorted(romeo_words)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q3\n",
    "points: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a bag-of-words model\n",
    "\n",
    "The simplest model for analyzing text is just to think about text as an unordered collection of words (bag-of-words). This can generally allow to infer from the text the category, the topic or the sentiment.\n",
    "\n",
    "From the bag-of-words model we can build features to be used by a classifier, here we assume that each word is a feature that can either be `True` or `False`.\n",
    "We implement this in Python as a dictionary where for each word in a sentence we associate `True`.\n",
    "\n",
    "2.1 **Write a function `build_bag_of_words(words)` that returns such a dictionary with {word : True} format given a set of words. Call the function with `romeo_words` and store the resultant dictionary as `romeo_word_dict`.** [1 pt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "def build_bag_of_words_features(words):\n",
    "    return {word:True for word in words}\n",
    "\n",
    "romeo_word_dict = build_bag_of_words_features(romeo_words)\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "def build_bag_of_words_features(words):\n",
    "    return ...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(build_bag_of_words_features(romeo_words)) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(value for value in romeo_word_dict.values() if value) == 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "ans_3 = build_bag_of_words_features(romeo_words)\n",
    "assert sorted(ans_3) == sorted(romeo_word_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we wanted, but we notice that also punctuation like \"!\" and words useless for classification purposes like \"of\" or \"that\" are also included.\n",
    "Those words are named \"stopwords\" and `nltk` has a convenient corpus we can download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ananshar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this cell\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this cell\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4\n",
    "points: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Python `string.punctuation` list and the English stopwords we can build better features by filtering out those words that would not help in the classification.\n",
    "\n",
    "2.2 **Create a list `useless_words` that is a collection of stopwords in english and the punctuation characters.** [0.5 pt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "useless_words = ...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(useless_words) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(useless_words) == 211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "ans_4 = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "assert sorted(ans_4) == sorted(useless_words)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q5\n",
    "points: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 **Write a function `build_bag_of_words_features_filtered(words)` that returns a filtered bag of words - a dictionary with only useful words as key and 1 as the value. Call this function with `romeo_words` and store the resultant dictionary as `romeo_useful_word_dict`.** [1 pt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "def build_bag_of_words_features_filtered(words):\n",
    "    return {\n",
    "        word:1 for word in words if not word in useless_words}\n",
    "\n",
    "romeo_useful_word_dict = build_bag_of_words_features_filtered(romeo_words)\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "def build_bag_of_words_features_filtered(words):\n",
    "    return ...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(build_bag_of_words_features_filtered(romeo_words)) == dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(romeo_useful_word_dict) == 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "ans_5 = build_bag_of_words_features_filtered(romeo_words)\n",
    "assert sorted(ans_5) == sorted(romeo_useful_word_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q6\n",
    "points: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Frequencies of Words\n",
    "\n",
    "It is common to explore a dataset before starting the analysis, in this section we will find the most common words and plot their frequency.\n",
    "\n",
    "3.1. Using the `movie_reviews.words()` (the nltk corpus we imported previously) with no argument we can extract the words from the entire dataset as `all_words` and check that it is about 1.6 millions. [0.5 pt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "all_words = movie_reviews.words()\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "all_words = ...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert len(all_words) == 1583820"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q7\n",
    "points: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Filter out `useless_words` as defined in the previous section, and create a new list `filtered_words` this will reduce the length of the dataset by more than a factor of 2. (Hint - Use python list comprehension) [0.5 pt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "filtered_words = [word for word in all_words if not word in useless_words]\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "filtered_words = ...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(filtered_words) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert len(filtered_words) == 710579"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `collection` package of the standard library contains a `Counter` class that is handy for counting frequencies of words in our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "from collections import Counter\n",
    "word_counter = Counter(filtered_words)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q8\n",
    "points: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 It also has a [most_common() ](https://pythontic.com/containers/counter/most_common) method of the word_counter and store the top 10 used words from the corpus in `most_common_words`. [0.5 pt]?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "most_common_words = word_counter.most_common(10)\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "most_common_words = ...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(most_common_words) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(most_common_words) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "assert most_common_words == [('film', 9517),('one', 5852),('movie', 5771),('like', 3690),('even', 2565),('good', 2411),('time', 2411),('story', 2169),('would', 2109),('much', 2049)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q9\n",
    "manual: true\n",
    "points: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis [2 pt]\n",
    "\n",
    "Using the sentiment intensity analyzer, loop over the `list_sentences` and print the polarity scores of each of the sentence. (Hint - refer to lecture notebook)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.4215}\n",
      "{'neg': 0.26, 'neu': 0.74, 'pos': 0.0, 'compound': -0.2755}\n",
      "{'neg': 0.369, 'neu': 0.631, 'pos': 0.0, 'compound': -0.6249}\n",
      "{'neg': 0.0, 'neu': 0.501, 'pos': 0.499, 'compound': 0.6114}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION NO PROMPT\n",
    "list_sentences = [\"Hello, how are you?\", \"Today is a nice day\", \"I don't like the food at the cafe\", \"This is the worst pizza I have ever had.\", \"The orange juice is delicious!\", \"I am late to class.\" ]\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "for sentence in list_sentences:\n",
    "    print(sia.polarity_scores(sentence))\n",
    "# END SOLUTION\n",
    "\n",
    "\"\"\" # BEGIN PROMPT\n",
    "list_sentences = [\"Hello, how are you?\", \"Today is a nice day\", \"I don't like the food at the cafe\", \"This is the worst pizza I have ever had.\", \"The orange juice is delicious!\", \"I am late to class.\" ]\n",
    "...\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Neural Networks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q10\n",
    "manual: true\n",
    "points: 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Experiment [2.5 pt]\n",
    "\n",
    "For this section, we will use the same notebook from the lecture videos and perform tests on it. We learned that neural networks consist of layers of interconnected neurons/nodes that make up the hidden layers with weights that work on incoming information using the activation function.\n",
    "\n",
    "Make a copy and run (run all) this [notebook](https://drive.google.com/file/d/1JtkYzdEHl1ijLvralyla_2bNgaPODCM0/view?usp=sharing). USE COLAB ONLY.\n",
    "\n",
    "Perform the following experiments and report the test accuracy and time taken (sum of time taken across 10 epochs while fitting).\n",
    "\n",
    "1. For example - Provided case<br>\n",
    "1st hidden layer - 128 nodes.\n",
    "Accuracy : 0.9781\n",
    "Time: 43s\n",
    "\n",
    "For the subsequent experiments, you need to make a change in the code cell [15] like this - <br>\n",
    "  ```model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(128, activation='relu'), #given hidden layer 1\n",
    "      tf.keras.layers.Dense(128, activation='relu'), #added this layer for Experiment 2\n",
    "      tf.keras.layers.Dense(10)])\n",
    "  ```\n",
    "\n",
    "2. Experiment 2 <br>\n",
    "1st hidden layer - 128 nodes.<br>\n",
    "2nd hidden layer - 128 nodes.<br>\n",
    "\n",
    "3. Experiment 3 <br>\n",
    "1st hidden layer - 256 nodes.<br>\n",
    "\n",
    "\n",
    "3. Experiment 4 <br>\n",
    "1st hidden layer - 256 nodes.<br>\n",
    "2nd hidden layer - 256 nodes.<br>\n",
    "\n",
    "\n",
    "4. Experiment 5 <br>\n",
    "1st hidden layer - 128 nodes.<br>\n",
    "2nd hidden layer - 128 nodes.<br>\n",
    "3rd hidden layer - 128 nodes.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN PROMPT\n",
    "# Experiment 1:\n",
    "# Accuracy:      Time:\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q11\n",
    "manual: true\n",
    "points: 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Inference [0.5 pt]\n",
    "What can you infer from the above experiments regarding accuracy and computation resources(time) by changing the number of layers/number of nodes each layer. For any of the experiment did the accuracy decrease unexpectedly - what could be the reason? [0.5 pt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # BEGIN PROMPT\n",
    "# Write your answer here\n",
    "\"\"\"; # END PROMPT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
